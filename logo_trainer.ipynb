{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTVqCAgSmie4"
      },
      "source": [
        "# Установка зависимостей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u3q60di584x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "%store -r\n",
        "\n",
        "root_dir = \"/content\"\n",
        "%store root_dir\n",
        "repo_dir = str(root_dir)+\"/kohya-trainer\"\n",
        "%store repo_dir\n",
        "tools_dir = str(root_dir)+\"/kohya-trainer/tools\"\n",
        "%store tools_dir \n",
        "finetune_dir = str(root_dir)+\"/kohya-trainer/finetune\"\n",
        "%store finetune_dir\n",
        "training_dir = str(root_dir)+\"/dreambooth\"\n",
        "%store training_dir\n",
        "\n",
        "repo_url = \"https://github.com/Linaqruf/kohya-trainer\"\n",
        "\n",
        "\n",
        "%cd {root_dir}\n",
        "!git clone {repo_url} {repo_dir}\n",
        "os.makedirs(repo_dir, exist_ok=True)\n",
        "os.makedirs(tools_dir, exist_ok=True)\n",
        "os.makedirs(finetune_dir, exist_ok=True)\n",
        "os.makedirs(training_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNn0g1pnHfk5"
      },
      "outputs": [],
      "source": [
        "%store -r\n",
        "\n",
        "%cd {repo_dir}\n",
        "\n",
        "accelerate_config = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "%store accelerate_config\n",
        "\n",
        "def install_dependencies():\n",
        "    !pip -q install --upgrade gallery-dl gdown imjoy-elfinder\n",
        "    !apt -q install liblz4-tool aria2\n",
        "    !pip -q install --upgrade -r requirements.txt\n",
        "    !pip install xformers\n",
        "\n",
        "    from accelerate.utils import write_basic_config\n",
        "    if not os.path.exists(accelerate_config):\n",
        "        write_basic_config(save_location=accelerate_config)\n",
        "\n",
        "install_dependencies()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Rl2zERHbBQ9W"
      },
      "outputs": [],
      "source": [
        "#@title ## 1.3 Вход в Huggingface hub\n",
        "from huggingface_hub import login\n",
        "%store -r\n",
        "\n",
        "#@markdown Введите свой huggingface-token\n",
        "write_token = \"\" #@param {type:\"string\"}\n",
        "login(write_token, add_to_git_credential=True)\n",
        "\n",
        "%store write_token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wmnsZwClN1XL"
      },
      "outputs": [],
      "source": [
        "#@title ## 1.4 Скачивание SD 1.5\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "%cd {root_dir}\n",
        "\n",
        "modelUrl = \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\"\n",
        "modelName = \"Stable-Diffusion-v1-5\"\n",
        "\n",
        "vaeUrl = 'https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt'\n",
        "vaeName = \"stablediffusion.vae.pt\" \n",
        "\n",
        "def install_model(checkpoint_name, url):\n",
        "  ext = \"ckpt\" if url.endswith(\".ckpt\") else \"safetensors\"\n",
        "\n",
        "  hf_token = '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' \n",
        "  user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "  !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {root_dir}/pre_trained_model -o {checkpoint_name}.{ext} \"{url}\"\n",
        "\n",
        "def install_vae(vae_name, url):\n",
        "  hf_token = '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'\n",
        "  user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "  !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -o vae/{vae_name} \"{url}\"\n",
        "\n",
        "\n",
        "install_model(modelName, modelUrl)\n",
        "install_vae(vaeName, vaeUrl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kh7CeDqK4l3Y"
      },
      "outputs": [],
      "source": [
        "#@title ## 1.5 Объявление директории для датасета\n",
        "%store -r\n",
        "\n",
        "parent_directory = \"/content/dreambooth/train_data\" #@param {type: \"string\"}\n",
        "%store parent_directory\n",
        "reg_folder_directory = os.path.join(os.path.dirname(parent_directory), \"reg_data\")\n",
        "%store reg_folder_directory\n",
        "\n",
        "reg_repeats = 1 #@param {type: \"integer\"}\n",
        "train_repeats = 22 #@param {type: \"integer\"}\n",
        "concept_name = \"LOGOGENA\" #@param {type: \"string\"}\n",
        "class_name = \"logo_generator\" #@param {type: \"string\"}\n",
        "\n",
        "def get_folder_name(repeats, class_name, concept_name=None):\n",
        "  if class_name:\n",
        "    return f\"{repeats}_{concept_name} {class_name}\" if concept_name else f\"{repeats}_{class_name}\"\n",
        "  return f\"{repeats}_{concept_name}\"\n",
        "\n",
        "train_folder = get_folder_name(train_repeats, class_name, concept_name=concept_name)\n",
        "reg_folder = get_folder_name(reg_repeats, class_name)\n",
        "\n",
        "train_data_dir = os.path.join(parent_directory, train_folder)\n",
        "reg_data_dir = os.path.join(reg_folder_directory, reg_folder)\n",
        "\n",
        "os.makedirs(parent_directory, exist_ok=True)\n",
        "os.makedirs(reg_folder_directory, exist_ok=True)\n",
        "os.makedirs(train_data_dir, exist_ok=True)\n",
        "os.makedirs(reg_data_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FzCGNU__caAz"
      },
      "outputs": [],
      "source": [
        "#@title ## 4.1. Конвентирование RGBA в RGB \n",
        "\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import concurrent.futures\n",
        "from PIL import Image\n",
        "random_color = False #@param {type:\"boolean\"}\n",
        "\n",
        "batch_size = 32 #@param {type:\"number\"}\n",
        "\n",
        "images = [image for image in os.listdir(train_data_dir) if image.endswith('.png') or image.endswith('.webp')]\n",
        "background_colors = [(255, 255, 255), \n",
        "                     (0, 0, 0), \n",
        "                     (255, 0, 0), \n",
        "                     (0, 255, 0), \n",
        "                     (0, 0, 255), \n",
        "                     (255, 255, 0), \n",
        "                     (255, 0, 255), \n",
        "                     (0, 255, 255)]\n",
        "\n",
        "def process_image(image_name):\n",
        "    img = Image.open(f'{train_data_dir}/{image_name}')\n",
        "\n",
        "    if img.mode in ('RGBA', 'LA'):\n",
        "        if random_color:\n",
        "          background_color = random.choice(background_colors)\n",
        "        else:\n",
        "          background_color = (255, 255, 255)\n",
        "        bg = Image.new('RGB', img.size, background_color)\n",
        "        bg.paste(img, mask=img.split()[-1])\n",
        "\n",
        "        if image_name.endswith('.webp'):\n",
        "            bg = bg.convert('RGB')\n",
        "            bg.save(f'{train_data_dir}/{image_name.replace(\".webp\", \".jpg\")}', \"JPEG\")\n",
        "            os.remove(f'{train_data_dir}/{image_name}')\n",
        "            print(f\" Converted image: {image_name} to {image_name.replace('.webp', '.jpg')}\")\n",
        "        else:\n",
        "            bg.save(f'{train_data_dir}/{image_name}', \"PNG\")\n",
        "            print(f\" Converted image: {image_name}\")\n",
        "    else:\n",
        "        if image_name.endswith('.webp'):\n",
        "            img.save(f'{train_data_dir}/{image_name.replace(\".webp\", \".jpg\")}', \"JPEG\")\n",
        "            os.remove(f'{train_data_dir}/{image_name}')\n",
        "            print(f\" Converted image: {image_name} to {image_name.replace('.webp', '.jpg')}\")\n",
        "        else:\n",
        "            img.save(f'{train_data_dir}/{image_name}', \"PNG\")\n",
        "\n",
        "num_batches = len(images) // batch_size + 1\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    for i in tqdm(range(num_batches)):\n",
        "        start = i * batch_size\n",
        "        end = start + batch_size\n",
        "        batch = images[start:end]\n",
        "        executor.map(process_image, batch)\n",
        "\n",
        "print(\"All images have been converted\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHNbl3O_NSS0"
      },
      "source": [
        "# Обучение модели\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_Q23fUEJhnC",
        "outputId": "43bf1a01-39f2-4896-9c08-73087bb39594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stored 'train_folder_directory' (str)\n",
            "Stored 'reg_folder_directory' (str)\n"
          ]
        }
      ],
      "source": [
        "#@title ## 3.1. Define Important folder\n",
        "from google.colab import drive\n",
        "%store -r\n",
        "\n",
        "project_name = \"LOGOGENA\" #@param {type:\"string\"}\n",
        "pretrained_model_name_or_path = \"/content/pre_trained_model/Stable-Diffusion-v1-5.ckpt\" #@param {type:\"string\"}\n",
        "vae = \"/content/vae/stablediffusion.vae.pt\"  #@param {type:\"string\"}\n",
        "train_folder_directory = \"/content/dreambooth/train_data\" #@param {'type':'string'}\n",
        "%store train_folder_directory\n",
        "reg_folder_directory = \"/content/dreambooth/reg_data\" \n",
        "%store reg_folder_directory\n",
        "output_dir = \"/content/dreambooth/output\" \n",
        "resume_path =\"\"\n",
        "inference_url = \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/\"\n",
        "\n",
        "#@markdown Поставьте галку для того, чтобы выход модели сохранялся на диске\n",
        "output_to_drive = False #@param {'type':'boolean'}\n",
        "\n",
        "if output_to_drive:\n",
        "  output_dir = \"/content/drive/MyDrive/dreambooth/output\"\n",
        "\n",
        "  if not os.path.exists(\"/content/drive\"):\n",
        "    drive.mount('/content/drive')  \n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5P-QVvHMUrFB"
      },
      "outputs": [],
      "source": [
        "#@title ## 3.2. Объявление параметров и запуск обучения\n",
        "%store -r\n",
        "\n",
        "\n",
        "network_dim = 128 #@param {'type':'number'}\n",
        "network_alpha = 128 #@param {'type':'number'}\n",
        "network_module = \"networks.lora\"\n",
        "\n",
        "network_train_on = \"both\" \n",
        "\n",
        "learning_rate = 1e-4 #@param {'type':'number'}\n",
        "unet_lr = 0 \n",
        "text_encoder_lr = 5e-4 #@param {'type':'number'}\n",
        "lr_scheduler = \"constant\" \n",
        "\n",
        "lr_scheduler_num_cycles = 1 \n",
        "lr_scheduler_power = 1 \n",
        "\n",
        "no_metadata = False \n",
        "\n",
        "train_batch_size = 1 #@param {type:\"number\"}\n",
        "num_epochs = 50 #@param {type:\"number\"}\n",
        "caption_extension = '.txt' #@param {'type':'string'}\n",
        "mixed_precision = \"fp16\" #@param [\"no\",\"fp16\",\"bf16\"] {allow-input: false}\n",
        "save_precision = \"fp16\" #@param [\"float\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "save_n_epochs_type = \"save_every_n_epochs\" #@param [\"save_every_n_epochs\", \"save_n_epoch_ratio\"] {allow-input: false}\n",
        "save_n_epochs_type_value = 5 #@param {type:\"number\"}\n",
        "save_model_as = \"safetensors\" #@param [\"ckpt\", \"pt\", \"safetensors\"] {allow-input: false}\n",
        "resolution = 512 #@param {type:\"slider\", min:512, max:1024, step:128}\n",
        "enable_bucket = False\n",
        "min_bucket_reso = 320 if resolution > 640 else 256\n",
        "max_bucket_reso = 1280 if resolution > 640 else 1024\n",
        "cache_latents = True \n",
        "max_token_length = 225 #@param {type:\"number\"}\n",
        "clip_skip = 1 #@param {type:\"number\"}\n",
        "use_8bit_adam = True \n",
        "gradient_checkpointing = False \n",
        "gradient_accumulation_steps = 1 \n",
        "seed = 0 \n",
        "logging_dir = \"/content/dreambooth/logs\"\n",
        "log_prefix = project_name\n",
        "additional_argument = \"--shuffle_caption --xformers\" \n",
        "print_hyperparameter = True \n",
        "prior_loss_weight = 1.0\n",
        "%cd {repo_dir}\n",
        "\n",
        "train_command=f\"\"\"\n",
        "accelerate launch --config_file={accelerate_config} --num_cpu_threads_per_process=8 train_network.py \\\n",
        "  {\"--v2\" if v2 else \"\"} \\\n",
        "  {\"--v_parameterization\" if v2 and v_parameterization else \"\"} \\\n",
        "  --network_dim={network_dim} \\\n",
        "  --network_alpha={network_alpha} \\\n",
        "  --network_module={network_module} \\\n",
        "  {\"--network_weights=\" + network_weights if network_weights else \"\"} \\\n",
        "  {\"--network_train_unet_only\" if network_train_on == \"unet_only\" else \"\"} \\\n",
        "  {\"--network_train_text_encoder_only\" if network_train_on == \"text_encoder_only\" else \"\"} \\\n",
        "  --learning_rate={learning_rate} \\\n",
        "  {\"--unet_lr=\" + format(unet_lr) if unet_lr !=0 else \"\"} \\\n",
        "  {\"--text_encoder_lr=\" + format(text_encoder_lr) if text_encoder_lr !=0 else \"\"} \\\n",
        "  {\"--no_metadata\" if no_metadata else \"\"} \\\n",
        "  {\"--training_comment=\" + training_comment if training_comment and not no_metadata else \"\"} \\\n",
        "  --lr_scheduler={lr_scheduler} \\\n",
        "  {\"--lr_scheduler_num_cycles=\" + format(lr_scheduler_num_cycles) if lr_scheduler == \"cosine_with_restarts\" else \"\"} \\\n",
        "  {\"--lr_scheduler_power=\" + format(lr_scheduler_power) if lr_scheduler == \"polynomial\" else \"\"} \\\n",
        "  --pretrained_model_name_or_path={pretrained_model_name_or_path} \\\n",
        "  {\"--vae=\" + vae if vae else \"\"} \\\n",
        "  {\"--caption_extension=\" + caption_extension if caption_extension else \"\"} \\\n",
        "  --train_data_dir={train_folder_directory} \\\n",
        "  --reg_data_dir={reg_folder_directory} \\\n",
        "  --output_dir={output_dir} \\\n",
        "  --prior_loss_weight={prior_loss_weight} \\\n",
        "  {\"--resume=\" + resume_path if resume_path else \"\"} \\\n",
        "  {\"--output_name=\" + project_name if project_name else \"\"} \\\n",
        "  --mixed_precision={mixed_precision} \\\n",
        "  --save_precision={save_precision} \\\n",
        "  {\"--save_every_n_epochs=\" + format(save_n_epochs_type_value) if save_n_epochs_type==\"save_every_n_epochs\" else \"\"} \\\n",
        "  {\"--save_n_epoch_ratio=\" + format(save_n_epochs_type_value) if save_n_epochs_type==\"save_n_epoch_ratio\" else \"\"} \\\n",
        "  --save_model_as={save_model_as} \\\n",
        "  --resolution={resolution} \\\n",
        "  {\"--enable_bucket\" if enable_bucket else \"\"} \\\n",
        "  {\"--min_bucket_reso=\" + format(min_bucket_reso) if enable_bucket else \"\"} \\\n",
        "  {\"--max_bucket_reso=\" + format(max_bucket_reso) if enable_bucket else \"\"} \\\n",
        "  {\"--cache_latents\" if cache_latents else \"\"} \\\n",
        "  --train_batch_size={train_batch_size} \\\n",
        "  --max_token_length={max_token_length} \\\n",
        "  {\"--use_8bit_adam\" if use_8bit_adam else \"\"} \\\n",
        "  --max_train_epochs={num_epochs} \\\n",
        "  {\"--seed=\" + format(seed) if seed > 0 else \"\"} \\\n",
        "  {\"--gradient_checkpointing\" if gradient_checkpointing else \"\"} \\\n",
        "  {\"--gradient_accumulation_steps=\" + format(gradient_accumulation_steps) } \\\n",
        "  {\"--clip_skip=\" + format(clip_skip) if v2 == False else \"\"} \\\n",
        "  --logging_dir={logging_dir} \\\n",
        "  --log_prefix={log_prefix} \\\n",
        "  {additional_argument}\n",
        "  \"\"\"\n",
        "\n",
        "debug_params = [\"v2\", \\\n",
        "                \"v_parameterization\", \\\n",
        "                \"network_dim\", \\\n",
        "                \"network_alpha\", \\\n",
        "                \"network_module\", \\\n",
        "                \"network_weights\", \\\n",
        "                \"network_train_on\", \\\n",
        "                \"learning_rate\", \\\n",
        "                \"unet_lr\", \\\n",
        "                \"text_encoder_lr\", \\\n",
        "                \"no_metadata\", \\\n",
        "                \"training_comment\", \\\n",
        "                \"lr_scheduler\", \\\n",
        "                \"lr_scheduler_num_cycles\", \\\n",
        "                \"lr_scheduler_power\", \\\n",
        "                \"pretrained_model_name_or_path\", \\\n",
        "                \"vae\", \\\n",
        "                \"caption_extension\", \\\n",
        "                \"train_folder_directory\", \\\n",
        "                \"reg_folder_directory\", \\\n",
        "                \"output_dir\", \\\n",
        "                \"prior_loss_weight\", \\\n",
        "                \"resume_path\", \\\n",
        "                \"project_name\", \\\n",
        "                \"mixed_precision\", \\\n",
        "                \"save_precision\", \\\n",
        "                \"save_n_epochs_type\", \\\n",
        "                \"save_n_epochs_type_value\", \\\n",
        "                \"save_model_as\", \\\n",
        "                \"resolution\", \\\n",
        "                \"enable_bucket\", \\\n",
        "                \"min_bucket_reso\", \\\n",
        "                \"max_bucket_reso\", \\\n",
        "                \"cache_latents\", \\\n",
        "                \"train_batch_size\", \\\n",
        "                \"max_token_length\", \\\n",
        "                \"use_8bit_adam\", \\\n",
        "                \"num_epochs\", \\\n",
        "                \"seed\", \\\n",
        "                \"gradient_checkpointing\", \\\n",
        "                \"gradient_accumulation_steps\", \\\n",
        "                \"clip_skip\", \\\n",
        "                \"logging_dir\", \\\n",
        "                \"log_prefix\", \\\n",
        "                \"additional_argument\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLSQslfFcQde",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ## 3.3. Вывод обучаюющей кривой\n",
        "training_logs_path = \"/content/dreambooth/logs\" #@param {type : \"string\"}\n",
        "\n",
        "%cd /content/kohya-trainer\n",
        "# %load_ext tensorboard\n",
        "%tensorboard --logdir {training_logs_path} --port 6007"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}