{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTVqCAgSmie4"
      },
      "source": [
        "# Установка зависимостей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u3q60di584x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "%store -r\n",
        "\n",
        "root_dir = \"/content\"\n",
        "%store root_dir\n",
        "repo_dir = str(root_dir)+\"/kohya-trainer\"\n",
        "%store repo_dir\n",
        "tools_dir = str(root_dir)+\"/kohya-trainer/tools\"\n",
        "%store tools_dir \n",
        "finetune_dir = str(root_dir)+\"/kohya-trainer/finetune\"\n",
        "%store finetune_dir\n",
        "training_dir = str(root_dir)+\"/dreambooth\"\n",
        "%store training_dir\n",
        "\n",
        "repo_url = \"https://github.com/Linaqruf/kohya-trainer\"\n",
        "\n",
        "\n",
        "%cd {root_dir}\n",
        "!git clone {repo_url} {repo_dir}\n",
        "os.makedirs(repo_dir, exist_ok=True)\n",
        "os.makedirs(tools_dir, exist_ok=True)\n",
        "os.makedirs(finetune_dir, exist_ok=True)\n",
        "os.makedirs(training_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNn0g1pnHfk5"
      },
      "outputs": [],
      "source": [
        "%store -r\n",
        "\n",
        "%cd {repo_dir}\n",
        "\n",
        "accelerate_config = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "%store accelerate_config\n",
        "\n",
        "def install_dependencies():\n",
        "    !pip -q install --upgrade gallery-dl gdown imjoy-elfinder\n",
        "    !apt -q install liblz4-tool aria2\n",
        "    !pip -q install --upgrade -r requirements.txt\n",
        "    !pip install xformers\n",
        "\n",
        "    from accelerate.utils import write_basic_config\n",
        "    if not os.path.exists(accelerate_config):\n",
        "        write_basic_config(save_location=accelerate_config)\n",
        "\n",
        "install_dependencies()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Rl2zERHbBQ9W"
      },
      "outputs": [],
      "source": [
        "#@title ## 1.3 Вход в Huggingface hub\n",
        "from huggingface_hub import login\n",
        "%store -r\n",
        "\n",
        "#@markdown Введите свой huggingface-token\n",
        "write_token = \"\" #@param {type:\"string\"}\n",
        "login(write_token, add_to_git_credential=True)\n",
        "\n",
        "%store write_token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wmnsZwClN1XL"
      },
      "outputs": [],
      "source": [
        "#@title ## 1.4 Скачивание SD 1.5\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "%cd {root_dir}\n",
        "\n",
        "modelUrl = \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\"\n",
        "modelName = \"Stable-Diffusion-v1-5\"\n",
        "\n",
        "vaeUrl = 'https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt'\n",
        "vaeName = \"stablediffusion.vae.pt\" \n",
        "\n",
        "def install_model(checkpoint_name, url):\n",
        "  ext = \"ckpt\" if url.endswith(\".ckpt\") else \"safetensors\"\n",
        "\n",
        "  hf_token = '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' \n",
        "  user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "  !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {root_dir}/pre_trained_model -o {checkpoint_name}.{ext} \"{url}\"\n",
        "\n",
        "def install_vae(vae_name, url):\n",
        "  hf_token = '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'\n",
        "  user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "  !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -o vae/{vae_name} \"{url}\"\n",
        "\n",
        "\n",
        "install_model(modelName, modelUrl)\n",
        "install_vae(vaeName, vaeUrl)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "gdown.download('https://drive.google.com/file/d/1YCgV6WYA3FGl7kG5_K39Qcp8rmTdKOLs/view?usp=share_link', output='/content/classifier_weights.pt', fuzzy=True)\n",
        "gdown.download('https://drive.google.com/file/d/1-SJqjt7uNIru83ixKPA6Hhtwa9ekZVHL/view?usp=share_link', output='/content/LOGOGENA_BEST_CONCEPTUAL.safetensors', fuzzy=True)\n",
        "gdown.download('https://drive.google.com/file/d/1tgVX53x-xav6B_OZgyA4MWduDCITbdXV/view?usp=share_link', output='/content/LOGOGENA_BEST_NOT_CONCEPTUAL.safetensors', fuzzy=True)"
      ],
      "metadata": {
        "id": "KJRPCZjZpjqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Применение модели генерации логотипов"
      ],
      "metadata": {
        "id": "mt5iFVuo4v5E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKBrTDPrcNjP",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "%store -r\n",
        "\n",
        "network_weights = \"/content/LOGOGENA_BEST_CONCEPTUAL.safetensors\" #@param {'type':'string'}\n",
        "network_module = \"networks.lora\"\n",
        "network_mul = 0.8\n",
        "v2 = False \n",
        "v_parameterization = False \n",
        "instance_prompt = \"LOGOGENA\"\n",
        "name = \"pepa\" #@param {type: \"string\"}\n",
        "activity = \"meat company\" #@param {type: \"string\"}\n",
        "tags = \"\" #@param {type: \"string\"}\n",
        "description = \"\" #@param {type: \"string\"}\n",
        "prompt = f\"name: {name}\\nactivity: {activity}\\ntags: {tags}\\ndescription: {description}\"\n",
        "negative = \"realistic, crooked text, inscription, title, error, extra digit, fewer digits, cropped, jpeg artifacts, signature, watermark, username, blurry\"\n",
        "model = \"/content/pre_trained_model/Stable-Diffusion-v1-5.ckpt\" \n",
        "vae = \"/content/vae/stablediffusion.vae.pt\" \n",
        "outdir = \"/content/tmp1\" #@param {type: \"string\"}\n",
        "scale = 5 \n",
        "sampler = \"ddim\" \n",
        "steps = 30 #@param {type: \"slider\", min: 1, max: 100}\n",
        "precision = \"fp16\" \n",
        "width = 512 #@param {type: \"integer\"}\n",
        "height = 512 #@param {type: \"integer\"}\n",
        "images_per_prompt = 9 #@param {type: \"integer\"}\n",
        "batch_size = images_per_prompt \n",
        "clip_skip = 1 \n",
        "seed = -1 \n",
        "\n",
        "\n",
        "final_prompt = f\"{instance_prompt}, {prompt} --n {negative}\" if instance_prompt else f\"{prompt} --n {negative}\"\n",
        "\n",
        "%cd {repo_dir}\n",
        "\n",
        "!python gen_img_diffusers.py \\\n",
        "{\"--v2\" if v2 else \"\"} \\\n",
        "{\"--v_parameterization\" if v2 and v_parameterization else \"\"} \\\n",
        "--network_module={network_module} \\\n",
        "--network_weight={network_weights} \\\n",
        "--network_mul={network_mul} \\\n",
        "--ckpt={model} \\\n",
        "--outdir={outdir} \\\n",
        "--xformers \\\n",
        "{\"--vae=\" + vae if vae else \"\"} \\\n",
        "--{precision} \\\n",
        "--W={width} \\\n",
        "--H={height} \\\n",
        "{\"--seed=\" + format(seed) if seed > 0 else \"\"} \\\n",
        "--scale={scale} \\\n",
        "--sampler={sampler} \\\n",
        "--steps={steps} \\\n",
        "--max_embeddings_multiples=3 \\\n",
        "--batch_size={batch_size} \\\n",
        "--images_per_prompt={images_per_prompt} \\\n",
        "{\"--clip_skip=\" + format(clip_skip) if v2 == False else \"\"} \\\n",
        "--prompt=\"{final_prompt}\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Классификатор для ранжирования"
      ],
      "metadata": {
        "id": "rHW4sHNTrjOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL.Image import Image as PilImage\n",
        "import textwrap, os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def load_model(weights_path):\n",
        "    class LinearNet(nn.Module):\n",
        "        def __init__(self, backbone):\n",
        "            super(LinearNet, self).__init__()\n",
        "            \n",
        "            self.backbone = backbone\n",
        "            self.backbone.fc = nn.Linear(512, 512)\n",
        "            self.fc = nn.Linear(512, 1)\n",
        "            self.sig = nn.Sigmoid()\n",
        "            \n",
        "        def forward(self, x):\n",
        "            x = self.backbone(F.normalize(x))\n",
        "            x = self.fc(F.normalize(x))\n",
        "            return self.sig(x)\n",
        "        \n",
        "    resnet = torchvision.models.resnet18(pretrained=True)\n",
        "    model = LinearNet(resnet)\n",
        "\n",
        "    model.load_state_dict(torch.load(weights_path))\n",
        "    return model\n",
        "\n",
        "def calc_score(model, ex):\n",
        "    return model(transform(ex).unsqueeze(0).to(device))\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "def display_images(\n",
        "    images, \n",
        "    titles,\n",
        "    columns=1, width=20, height=8, max_images=15, \n",
        "    label_wrap_length=50, label_font_size=18):\n",
        "\n",
        "    if not images:\n",
        "        print(\"No images to display.\")\n",
        "        return \n",
        "\n",
        "    if len(images) > max_images:\n",
        "        print(f\"Showing {max_images} images of {len(images)}:\")\n",
        "        images=images[0:max_images]\n",
        "\n",
        "    height = max(height, int(len(images)/columns) * height)\n",
        "    plt.figure(figsize=(width, height))\n",
        "    for i, image in enumerate(images):\n",
        "\n",
        "        plt.subplot(int(len(images) / columns + 1), columns, i + 1)\n",
        "        plt.imshow(image)\n",
        "        \n",
        "        title = 1-titles[i]\n",
        "        plt.title(f'LOGO Score: {\"{0:0.2f}\".format(title)}', fontsize=label_font_size)\n",
        "        plt.axis('off')"
      ],
      "metadata": {
        "id": "VRQVQZouub-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/classifier_weights.pt').to(device)\n",
        "model.eval()\n",
        "\n",
        "scores = []\n",
        "for filename in os.listdir(outdir):\n",
        "    ex = Image.open(os.path.join(outdir, filename)).convert('RGB')\n",
        "    scores.append((\n",
        "        model(transform(ex).unsqueeze(0).to(device))[0][0].item(),\n",
        "        ex\n",
        "        ))\n",
        "    \n",
        "scores.sort()\n",
        "images = [i[1] for i in scores]\n",
        "titles = [i[0] for i in scores]"
      ],
      "metadata": {
        "id": "S2CPbq18o45H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ранжированные логотипы"
      ],
      "metadata": {
        "id": "MTxniKh5rq2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_images(images, titles)"
      ],
      "metadata": {
        "id": "JAutCtaApRBr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}